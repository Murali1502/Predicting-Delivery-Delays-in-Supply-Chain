{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T18:18:41.877762Z",
     "start_time": "2025-11-18T18:17:38.369676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, classification_report,\n",
    "                             confusion_matrix, roc_curve)\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Data Loading and Initial Cleaning ---\n",
    "print(\"=\"*80)\n",
    "print(\"SUPPLY CHAIN LATE DELIVERY RISK PREDICTION MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Loading and Cleaning Data...\")\n",
    "data = pd.read_csv(\"DataCoSupplyChainDataset.csv\", encoding=\"ISO-8859-1\")\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Basic data exploration\n",
    "print(f\"   Dataset shape: {data.shape}\")\n",
    "print(f\"   Columns: {data.shape[1]}\")\n",
    "missing = data.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(f\"\\n   Missing values:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"   No missing values detected\")\n",
    "\n",
    "# --- 2. Enhanced Feature Engineering ---\n",
    "print(\"\\n2. Engineering Features...\")\n",
    "data['order_date'] = pd.to_datetime(data['order date (DateOrders)'], errors='coerce')\n",
    "\n",
    "# Temporal features\n",
    "data['order_hour'] = data['order_date'].dt.hour\n",
    "data['order_day_of_week'] = data['order_date'].dt.dayofweek\n",
    "data['order_month'] = data['order_date'].dt.month\n",
    "data['order_quarter'] = data['order_date'].dt.quarter\n",
    "data['order_day_of_month'] = data['order_date'].dt.day\n",
    "data['is_weekend'] = (data['order_day_of_week'] >= 5).astype(int)\n",
    "data['is_business_hours'] = ((data['order_hour'] >= 9) & (data['order_hour'] <= 17)).astype(int)\n",
    "data['is_month_end'] = (data['order_day_of_month'] >= 25).astype(int)\n",
    "\n",
    "# Product/Order interaction features\n",
    "if 'Order Item Quantity' in data.columns and 'Order Item Discount' in data.columns:\n",
    "    data['discount_per_item'] = data['Order Item Discount'] / (data['Order Item Quantity'] + 1)\n",
    "    data['high_discount_flag'] = (data['Order Item Discount'] > data['Order Item Discount'].quantile(0.75)).astype(int)\n",
    "\n",
    "if 'Sales' in data.columns and 'Order Item Quantity' in data.columns:\n",
    "    data['price_per_item'] = data['Sales'] / (data['Order Item Quantity'] + 1)\n",
    "\n",
    "# Shipping complexity score\n",
    "if 'Days for shipment (scheduled)' in data.columns:\n",
    "    data['urgent_shipment'] = (data['Days for shipment (scheduled)'] <= 2).astype(int)\n",
    "\n",
    "# Drop invalid rows\n",
    "initial_rows = len(data)\n",
    "data = data.dropna(subset=['order_date', 'Late_delivery_risk'])\n",
    "print(f\"   Rows removed due to missing critical data: {initial_rows - len(data)}\")\n",
    "print(f\"   Rows after cleaning: {len(data)}\")\n",
    "\n",
    "# --- 3. Target and Feature Selection ---\n",
    "print(\"\\n3. Selecting Features and Target...\")\n",
    "y = data['Late_delivery_risk'].astype(int)\n",
    "print(f\"\\n   Target distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\n   Target proportions:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Feature selection (EXCLUDING potential leakage features)\n",
    "# Features known AT ORDER TIME only\n",
    "features = [\n",
    "    # Temporal features\n",
    "    'Days for shipment (scheduled)',\n",
    "    'order_hour',\n",
    "    'order_day_of_week',\n",
    "    'order_month',\n",
    "    'order_quarter',\n",
    "    'order_day_of_month',\n",
    "    'is_weekend',\n",
    "    'is_business_hours',\n",
    "    'is_month_end',\n",
    "\n",
    "    # Operational features\n",
    "    'Shipping Mode',\n",
    "    'Type',  # Payment Type\n",
    "\n",
    "    # Product/Department features\n",
    "    'Department Id',\n",
    "    'Category Id',\n",
    "    'Product Category Id',\n",
    "\n",
    "    # Order characteristics\n",
    "    'Order Item Quantity',\n",
    "    'Order Item Discount',\n",
    "    'Order Item Profit Ratio',\n",
    "    'Sales',\n",
    "    'Order Item Total',\n",
    "\n",
    "    # Engineered features\n",
    "    'discount_per_item',\n",
    "    'high_discount_flag',\n",
    "    'price_per_item',\n",
    "    'urgent_shipment'\n",
    "]\n",
    "\n",
    "# Verify features exist\n",
    "features = [f for f in features if f in data.columns]\n",
    "print(f\"   Total features selected: {len(features)}\")\n",
    "print(f\"   Features: {features}\")\n",
    "\n",
    "X = data[features].copy()\n",
    "\n",
    "# Handle missing values more carefully\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"\\n   Numeric features: {len(numeric_features)}\")\n",
    "print(f\"   Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Fill missing values\n",
    "for col in numeric_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna(X[col].median(), inplace=True)\n",
    "\n",
    "for col in categorical_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "# --- 4. Train-Test Split ---\n",
    "print(\"\\n4. Splitting Data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"   Train set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set:  {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n   Train target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# --- 5. Preprocessing Setup ---\n",
    "print(\"\\n5. Setting up Preprocessing Pipeline...\")\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=50), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# --- 6. Model Training ---\n",
    "print(\"\\n6. Training Models...\")\n",
    "\n",
    "# Calculate class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"   Class imbalance ratio: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# XGBoost with optimized parameters\n",
    "pipe_xgb = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=0.1,  # L1 regularization\n",
    "        reg_lambda=1.0   # L2 regularization\n",
    "    ))\n",
    "])\n",
    "\n",
    "# RandomForest with balanced weights\n",
    "pipe_rf = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train models\n",
    "print(\"   Training XGBoost...\")\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "print(\"   ✓ XGBoost trained\")\n",
    "\n",
    "print(\"   Training RandomForest...\")\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "print(\"   ✓ RandomForest trained\")\n",
    "\n",
    "# --- 7. Cross-Validation ---\n",
    "print(\"\\n7. Cross-Validation (5-Fold)...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"   XGBoost CV Scores:\")\n",
    "cv_scores_xgb = cross_val_score(pipe_xgb, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"      Mean AUC: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
    "\n",
    "print(\"   RandomForest CV Scores:\")\n",
    "cv_scores_rf = cross_val_score(pipe_rf, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"      Mean AUC: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
    "\n",
    "# --- 8. Enhanced Evaluation ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. MODEL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate(name, model, X_train, y_train, X_test, y_test):\n",
    "    # Train predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "\n",
    "    # Test predictions\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, test_preds)\n",
    "    prec = precision_score(y_test, test_preds, zero_division=0)\n",
    "    rec = recall_score(y_test, test_preds, zero_division=0)\n",
    "    f1 = f1_score(y_test, test_preds, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, test_probs)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, test_preds)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"  {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision:      {prec:.4f} (of predicted late, % actually late)\")\n",
    "    print(f\"  Recall:         {rec:.4f} (of actual late, % predicted late)\")\n",
    "    print(f\"  F1 Score:       {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC:        {auc:.4f}\")\n",
    "\n",
    "    print(f\"\\n  Confusion Matrix:\")\n",
    "    print(f\"                Predicted\")\n",
    "    print(f\"                On-Time  Late\")\n",
    "    print(f\"  Actual On-Time  {cm[0][0]:6d}  {cm[0][1]:5d}\")\n",
    "    print(f\"  Actual Late     {cm[1][0]:6d}  {cm[1][1]:5d}\")\n",
    "\n",
    "    print(f\"\\n  Classification Report:\")\n",
    "    print(classification_report(y_test, test_preds, target_names=['On-Time', 'Late']))\n",
    "\n",
    "    # Calculate business metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"  Specificity (True Negative Rate): {specificity:.4f}\")\n",
    "\n",
    "    return auc, test_probs, test_preds\n",
    "\n",
    "auc_xgb, probs_xgb, preds_xgb = evaluate(\"XGBoost\", pipe_xgb, X_train, y_train, X_test, y_test)\n",
    "auc_rf, probs_rf, preds_rf = evaluate(\"RandomForest\", pipe_rf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# --- 9. Feature Importance ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. FEATURE IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_feature_importance(model, name, top_n=20):\n",
    "    if hasattr(model.named_steps['clf'], 'feature_importances_'):\n",
    "        # Get feature names\n",
    "        cat_features = model.named_steps['pre'].named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "        feature_names = numeric_cols + list(cat_features)\n",
    "\n",
    "        # Get importances\n",
    "        importances = model.named_steps['clf'].feature_importances_\n",
    "\n",
    "        # Create DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        print(f\"\\n{name} - Top {top_n} Features:\")\n",
    "        print(importance_df.head(top_n).to_string(index=False))\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top_features = importance_df.head(top_n)\n",
    "        plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title(f'{name} - Top {top_n} Feature Importances')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'models_fixed/{name.lower()}_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"   ✓ Feature importance plot saved: {name.lower()}_feature_importance.png\")\n",
    "        plt.close()\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "os.makedirs(\"models_fixed\", exist_ok=True)\n",
    "importance_xgb = plot_feature_importance(pipe_xgb, \"XGBoost\", top_n=20)\n",
    "importance_rf = plot_feature_importance(pipe_rf, \"RandomForest\", top_n=20)\n",
    "\n",
    "# --- 10. ROC Curve Visualization ---\n",
    "print(\"\\n10. Generating ROC Curves...\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# XGBoost ROC\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, probs_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.4f})', linewidth=2)\n",
    "\n",
    "# RandomForest ROC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, probs_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC = {auc_rf:.4f})', linewidth=2)\n",
    "\n",
    "# Random baseline\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5000)', linewidth=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Late Delivery Prediction', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('models_fixed/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"   ✓ ROC curve saved: roc_curves.png\")\n",
    "plt.close()\n",
    "\n",
    "# --- 11. Save Best Model ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"11. SAVING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model_name = \"XGBoost\" if auc_xgb >= auc_rf else \"RandomForest\"\n",
    "best_model = pipe_xgb if auc_xgb >= auc_rf else pipe_rf\n",
    "best_auc = max(auc_xgb, auc_rf)\n",
    "\n",
    "# Save models\n",
    "pickle.dump(best_model, open(\"models_fixed/best_model.pkl\", \"wb\"))\n",
    "pickle.dump(pipe_xgb, open(\"models_fixed/xgb_model.pkl\", \"wb\"))\n",
    "pickle.dump(pipe_rf, open(\"models_fixed/rf_model.pkl\", \"wb\"))\n",
    "\n",
    "print(f\"   ✓ Best model: {best_model_name} (AUC: {best_auc:.4f})\")\n",
    "print(f\"   ✓ Models saved to 'models_fixed/' directory\")\n",
    "\n",
    "# --- 12. Save Metadata ---\n",
    "print(\"\\n12. Saving Model Metadata...\")\n",
    "\n",
    "# Feature list\n",
    "with open(\"models_fixed/feature_list.txt\", \"w\") as f:\n",
    "    f.write(\"# Features used for prediction (known at order time)\\n\")\n",
    "    f.write(\"# Generated: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\\n\")\n",
    "    f.write(\"\\n\".join(features))\n",
    "\n",
    "# Model metadata\n",
    "metadata = {\n",
    "    'training_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'best_model': best_model_name,\n",
    "    'best_auc': float(best_auc),\n",
    "    'xgb_auc': float(auc_xgb),\n",
    "    'rf_auc': float(auc_rf),\n",
    "    'xgb_cv_mean': float(cv_scores_xgb.mean()),\n",
    "    'rf_cv_mean': float(cv_scores_rf.mean()),\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'num_features': len(features),\n",
    "    'class_imbalance_ratio': float(scale_pos_weight),\n",
    "    'feature_list': features,\n",
    "    'numeric_features': numeric_cols,\n",
    "    'categorical_features': categorical_cols\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"models_fixed/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"   ✓ Feature list saved: feature_list.txt\")\n",
    "print(\"   ✓ Model metadata saved: model_metadata.json\")\n",
    "\n",
    "# --- 13. Model Performance Summary ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test ROC-AUC: {best_auc:.4f}\")\n",
    "print(f\"\\nAll outputs saved to: models_fixed/\")\n",
    "print(\"\\nFiles generated:\")\n",
    "print(\"  - best_model.pkl (production model)\")\n",
    "print(\"  - xgb_model.pkl\")\n",
    "print(\"  - rf_model.pkl\")\n",
    "print(\"  - feature_list.txt\")\n",
    "print(\"  - model_metadata.json\")\n",
    "print(\"  - xgboost_feature_importance.png\")\n",
    "print(\"  - randomforest_feature_importance.png\")\n",
    "print(\"  - roc_curves.png\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ],
   "id": "66907469eaa0fb3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUPPLY CHAIN LATE DELIVERY RISK PREDICTION MODEL\n",
      "================================================================================\n",
      "\n",
      "1. Loading and Cleaning Data...\n",
      "   Dataset shape: (180519, 53)\n",
      "   Columns: 53\n",
      "\n",
      "   Missing values:\n",
      "Customer Lname              8\n",
      "Customer Zipcode            3\n",
      "Order Zipcode          155679\n",
      "Product Description    180519\n",
      "dtype: int64\n",
      "\n",
      "2. Engineering Features...\n",
      "   Rows removed due to missing critical data: 0\n",
      "   Rows after cleaning: 180519\n",
      "\n",
      "3. Selecting Features and Target...\n",
      "\n",
      "   Target distribution:\n",
      "Late_delivery_risk\n",
      "1    98977\n",
      "0    81542\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Target proportions:\n",
      "Late_delivery_risk\n",
      "1    0.548291\n",
      "0    0.451709\n",
      "Name: proportion, dtype: float64\n",
      "   Total features selected: 23\n",
      "   Features: ['Days for shipment (scheduled)', 'order_hour', 'order_day_of_week', 'order_month', 'order_quarter', 'order_day_of_month', 'is_weekend', 'is_business_hours', 'is_month_end', 'Shipping Mode', 'Type', 'Department Id', 'Category Id', 'Product Category Id', 'Order Item Quantity', 'Order Item Discount', 'Order Item Profit Ratio', 'Sales', 'Order Item Total', 'discount_per_item', 'high_discount_flag', 'price_per_item', 'urgent_shipment']\n",
      "\n",
      "   Numeric features: 21\n",
      "   Categorical features: 2\n",
      "\n",
      "4. Splitting Data...\n",
      "   Train set: 144415 samples (80.0%)\n",
      "   Test set:  36104 samples (20.0%)\n",
      "\n",
      "   Train target distribution:\n",
      "Late_delivery_risk\n",
      "1    0.548288\n",
      "0    0.451712\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "5. Setting up Preprocessing Pipeline...\n",
      "\n",
      "6. Training Models...\n",
      "   Class imbalance ratio: 0.82\n",
      "   Training XGBoost...\n",
      "   ✓ XGBoost trained\n",
      "   Training RandomForest...\n",
      "   ✓ RandomForest trained\n",
      "\n",
      "7. Cross-Validation (5-Fold)...\n",
      "   XGBoost CV Scores:\n",
      "      Mean AUC: 0.7756 (+/- 0.0012)\n",
      "   RandomForest CV Scores:\n",
      "      Mean AUC: 0.7834 (+/- 0.0018)\n",
      "\n",
      "================================================================================\n",
      "8. MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "  XGBoost\n",
      "================================================================================\n",
      "  Train Accuracy: 0.7239\n",
      "  Test Accuracy:  0.7193\n",
      "  Precision:      0.8540 (of predicted late, % actually late)\n",
      "  Recall:         0.5887 (of actual late, % predicted late)\n",
      "  F1 Score:       0.6969\n",
      "  ROC-AUC:        0.7804\n",
      "\n",
      "  Confusion Matrix:\n",
      "                Predicted\n",
      "                On-Time  Late\n",
      "  Actual On-Time   14315   1993\n",
      "  Actual Late       8142  11654\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     On-Time       0.64      0.88      0.74     16308\n",
      "        Late       0.85      0.59      0.70     19796\n",
      "\n",
      "    accuracy                           0.72     36104\n",
      "   macro avg       0.75      0.73      0.72     36104\n",
      "weighted avg       0.76      0.72      0.72     36104\n",
      "\n",
      "  Specificity (True Negative Rate): 0.8778\n",
      "\n",
      "================================================================================\n",
      "  RandomForest\n",
      "================================================================================\n",
      "  Train Accuracy: 0.7226\n",
      "  Test Accuracy:  0.7205\n",
      "  Precision:      0.8577 (of predicted late, % actually late)\n",
      "  Recall:         0.5877 (of actual late, % predicted late)\n",
      "  F1 Score:       0.6975\n",
      "  ROC-AUC:        0.7858\n",
      "\n",
      "  Confusion Matrix:\n",
      "                Predicted\n",
      "                On-Time  Late\n",
      "  Actual On-Time   14378   1930\n",
      "  Actual Late       8161  11635\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     On-Time       0.64      0.88      0.74     16308\n",
      "        Late       0.86      0.59      0.70     19796\n",
      "\n",
      "    accuracy                           0.72     36104\n",
      "   macro avg       0.75      0.73      0.72     36104\n",
      "weighted avg       0.76      0.72      0.72     36104\n",
      "\n",
      "  Specificity (True Negative Rate): 0.8817\n",
      "\n",
      "================================================================================\n",
      "9. FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "XGBoost - Top 20 Features:\n",
      "                      Feature  Importance\n",
      "              urgent_shipment    0.309648\n",
      "Days for shipment (scheduled)    0.289704\n",
      "    Shipping Mode_First Class    0.161580\n",
      "       Shipping Mode_Same Day    0.114908\n",
      "                Type_TRANSFER    0.030573\n",
      "   Shipping Mode_Second Class    0.021828\n",
      "                   order_hour    0.017104\n",
      "                    Type_CASH    0.004405\n",
      "                   Type_DEBIT    0.004064\n",
      "                 Type_PAYMENT    0.003938\n",
      " Shipping Mode_Standard Class    0.002583\n",
      "                  order_month    0.002504\n",
      "           order_day_of_month    0.002486\n",
      "                order_quarter    0.002475\n",
      "            order_day_of_week    0.002463\n",
      "            discount_per_item    0.002261\n",
      "           high_discount_flag    0.002248\n",
      "                 is_month_end    0.002226\n",
      "             Order Item Total    0.002194\n",
      "          Order Item Discount    0.002176\n",
      "   ✓ Feature importance plot saved: xgboost_feature_importance.png\n",
      "\n",
      "RandomForest - Top 20 Features:\n",
      "                      Feature  Importance\n",
      "              urgent_shipment    0.169330\n",
      " Shipping Mode_Standard Class    0.133729\n",
      "Days for shipment (scheduled)    0.133637\n",
      "    Shipping Mode_First Class    0.106338\n",
      "                   order_hour    0.099940\n",
      "   Shipping Mode_Second Class    0.047174\n",
      "       Shipping Mode_Same Day    0.046438\n",
      "      Order Item Profit Ratio    0.028342\n",
      "           order_day_of_month    0.027902\n",
      "             Order Item Total    0.024858\n",
      "            discount_per_item    0.023564\n",
      "          Order Item Discount    0.022810\n",
      "                  order_month    0.017911\n",
      "                Type_TRANSFER    0.015865\n",
      "            order_day_of_week    0.015471\n",
      "               price_per_item    0.013182\n",
      "                        Sales    0.012308\n",
      "          Product Category Id    0.009236\n",
      "                  Category Id    0.009107\n",
      "                order_quarter    0.007568\n",
      "   ✓ Feature importance plot saved: randomforest_feature_importance.png\n",
      "\n",
      "10. Generating ROC Curves...\n",
      "   ✓ ROC curve saved: roc_curves.png\n",
      "\n",
      "================================================================================\n",
      "11. SAVING MODELS\n",
      "================================================================================\n",
      "   ✓ Best model: RandomForest (AUC: 0.7858)\n",
      "   ✓ Models saved to 'models_fixed/' directory\n",
      "\n",
      "12. Saving Model Metadata...\n",
      "   ✓ Feature list saved: feature_list.txt\n",
      "   ✓ Model metadata saved: model_metadata.json\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Best Model: RandomForest\n",
      "Test ROC-AUC: 0.7858\n",
      "\n",
      "All outputs saved to: models_fixed/\n",
      "\n",
      "Files generated:\n",
      "  - best_model.pkl (production model)\n",
      "  - xgb_model.pkl\n",
      "  - rf_model.pkl\n",
      "  - feature_list.txt\n",
      "  - model_metadata.json\n",
      "  - xgboost_feature_importance.png\n",
      "  - randomforest_feature_importance.png\n",
      "  - roc_curves.png\n",
      "\n",
      "================================================================================\n",
      "MODEL TRAINING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
